{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now reload\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "source_dir_name = 'clahe_processed'\n",
    "source_path = Path(os.environ['DATA_TEMP']) / 'chest-nihcc' / '128x128' / source_dir_name\n",
    "processed_imgs = {}\n",
    "for npy_filepath in list(source_path.glob('*.npy'))[:1000]:\n",
    "    import numpy as np\n",
    "    processed_imgs[npy_filepath.stem] = np.load(npy_filepath)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Loaded {len(processed_imgs)} npy in {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img = list(processed_imgs.values())[0]\n",
    "sz = one_img.shape[0]\n",
    "processed_imgs = {tpl[0]:np.reshape(tpl[1], (sz,sz,1)) for tpl in processed_imgs.items()}\n",
    "print(f\"Processed images are {sz}x{sz}x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = int(len(processed_imgs)/10)\n",
    "processed_img_list = list(processed_imgs.values())\n",
    "x_test = processed_img_list[:test_count]\n",
    "x_train = processed_img_list[test_count:]\n",
    "x_train, x_test = np.array(x_train), np.array(x_test)\n",
    "print(f\"Training data has shape {x_train.shape}\")\n",
    "print(f\"Testing data has shape {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load zebrastack_v0_model.py\n",
    "from tensorflow.keras.layers import Dense, Input, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Lambda\n",
    "from tensorflow.keras.layers import LocallyConnected2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.layers import ActivityRegularization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "sz = 128\n",
    "latent_dim = 12\n",
    "locally_connected_channels = 2\n",
    "do_plot_model = False\n",
    "cit_decimate = False\n",
    "act_func = 'softplus' # or 'relu'\n",
    "use_mse = False\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    instead of sampling from Q(z|X), sample eps = N(0,I) \n",
    "        then z = z_mean + sqrt(var)*eps    \n",
    "    # Arguments\n",
    "        args (tensor tuple): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"    \n",
    "    z_mean, z_log_var = args\n",
    "    \n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def vae_loss(z_mean, z_log_var, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute VAE loss, using either mse or crossentropy.\n",
    "    # Arguments\n",
    "        z_mean: mean of Q(z|X)\n",
    "        z_log_var: log variance of Q(z|X)\n",
    "        y_true, y_pred: truth and predicated values\n",
    "    # Returns\n",
    "        loss value\n",
    "    \"\"\"\n",
    "    img_pixels = 1.0 # sz * sz * 100.0\n",
    "    if use_mse:\n",
    "        match_loss = mse(K.flatten(y_true), K.flatten(y_pred)) * img_pixels\n",
    "    else:\n",
    "        match_loss = img_pixels * \\\n",
    "            binary_crossentropy(K.flatten(y_true), K.flatten(y_pred))\n",
    "            # binary_crossentropy(K.flatten(y_true), K.flatten(y_pred))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return match_loss + (1e-6 * kl_loss)\n",
    "\n",
    "def create_encoder():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # create encoder side\n",
    "    retina = Input(shape=(sz,sz,1), name='retina_{}'.format(sz))\n",
    "\n",
    "    v1_conv2d = Conv2D(32, (5,5), name='v1_conv2d', activation=act_func, padding='same')(retina)\n",
    "    v1_maxpool = MaxPooling2D((2,2), name='v1_maxpool', padding='same')(v1_conv2d)\n",
    "    v1_dropout = SpatialDropout2D(0.1, name='v1_dropout')(v1_maxpool)\n",
    "\n",
    "    v2_conv2d = Conv2D(64, (1,1), name='v2_conv2d', activation=act_func, padding='same')(v1_dropout)\n",
    "    v2_maxpool = MaxPooling2D((2,2), name='v2_maxpool', padding='same')(v2_conv2d)\n",
    "\n",
    "    v4_conv2d = Conv2D(64, (3,3), name='v4_conv2d', activation=act_func, padding='same')(v2_maxpool)\n",
    "    v4_maxpool = MaxPooling2D((2,2), name='v4_maxpool', padding='same')(v4_conv2d)\n",
    "\n",
    "    pit_conv2d = Conv2D(64, (1,1), name='pit_conv2d', activation=act_func, padding='same')(v4_maxpool)\n",
    "    pit_maxpool = MaxPooling2D((2,2), name='pit_maxpool', padding='same')(pit_conv2d)\n",
    "\n",
    "    cit_conv2d = Conv2D(64, (3,3), name='cit_conv2d', activation=act_func, padding='same')(pit_maxpool)\n",
    "    if cit_decimate:\n",
    "        cit_maxpool = MaxPooling2D((2,2), name='cit_maxpool', padding='same')(cit_conv2d)\n",
    "        cit_out = cit_maxpool\n",
    "    else:\n",
    "        cit_out = cit_conv2d\n",
    "\n",
    "    ait_local = LocallyConnected2D(locally_connected_channels, (3,3), \n",
    "                                   name='ait_local', activation=act_func)(cit_out)\n",
    "    # ait_padding = ZeroPadding2D(padding=(1,1), name='ait_padding')(ait_local)\n",
    "    # x = MaxPooling2D((2,2), padding='same', name='ait_maxpool')(ait_padding)\n",
    "\n",
    "    ait_regular = ActivityRegularization(l1=0.0e-4, l2=0.0e-4, name='ait_regular')(ait_local)\n",
    "\n",
    "    # shape info needed to build decoder model\n",
    "    shape = K.int_shape(ait_regular)\n",
    "    # print(shape)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    pulvinar_flatten = Flatten(name='pulvinar_flatten')(ait_regular)\n",
    "    pulvinar_dense = Dense(latent_dim, activation=act_func, name='pulvinar_dense')(pulvinar_flatten)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(pulvinar_dense)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(pulvinar_dense)\n",
    "\n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    encoder = Model(retina, [z_mean, z_log_var, z], name='v1_to_pulvinar_encoder')\n",
    "    encoder.summary()\n",
    "    \n",
    "    if do_plot_model: \n",
    "        plot_model(encoder, to_file='data\\{}.png'.format(encoder.name), show_shapes=True)\n",
    "\n",
    "    return retina, encoder, shape, [z_mean, z_log_var, z]\n",
    "\n",
    "def create_decoder(shape):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    pulvinar_dense_back = Dense(shape[1] * shape[2] * shape[3], name='pulvinar_dense_back', \n",
    "                                activation=act_func)(latent_inputs)\n",
    "    pulvinar_antiflatten = Reshape((shape[1], shape[2], shape[3]), name='pulvinar_antiflatten')(pulvinar_dense_back)\n",
    "\n",
    "    ait_padding_back = ZeroPadding2D(padding=(1,1), name='ait_padding_back')(pulvinar_antiflatten)\n",
    "    ait_local_back = LocallyConnected2D(locally_connected_channels, (3,3), name='ait_local_back', \n",
    "                                        activation=act_func)(ait_padding_back)\n",
    "\n",
    "    cit_padding_back = ZeroPadding2D(padding=(1,1), name='cit_padding_back')(ait_local_back)\n",
    "    if cit_decimate:\n",
    "        ait_upsample_back = UpSampling2D((2,2), name='ait_upsample_back')(cit_padding_back)\n",
    "        ait_out_back = ait_upsample_back\n",
    "    else:\n",
    "        ait_out_back = cit_padding_back\n",
    "\n",
    "    cit_conv2d_trans = Conv2DTranspose(64, (3,3), name='cit_conv2d_trans', \n",
    "                                       activation=act_func, padding='same')(ait_out_back)\n",
    "    cit_upsample_back = UpSampling2D((2,2), name='cit_upsample_back')(cit_conv2d_trans)\n",
    "\n",
    "    pit_conv2d_trans = Conv2DTranspose(64, (1,1), name='pit_conv2d_trans', \n",
    "                                       activation=act_func, padding='same')(cit_upsample_back)\n",
    "    pit_upsample_back = UpSampling2D((2,2), name='pit_upsample_back')(pit_conv2d_trans)\n",
    "\n",
    "    v4_conv2d_trans = Conv2DTranspose(64, (3,3), name='v4_conv2d_trans', \n",
    "                                      activation=act_func, padding='same')(pit_upsample_back)\n",
    "    v4_upsample_back = UpSampling2D((2,2), name='v4_upsample_back')(v4_conv2d_trans)\n",
    "\n",
    "    v2_conv2d_trans = Conv2DTranspose(32, (1,1), name='v2_conv2d_trans', \n",
    "                                      activation=act_func, padding='same')(v4_upsample_back)\n",
    "    v2_upsample_back = UpSampling2D((2,2), name='v2_upsample_back')(v2_conv2d_trans)\n",
    "\n",
    "    v1_conv2d_5x5_back = Conv2DTranspose(1, (5,5), name='v1_conv2d_5x5_back', \n",
    "                                activation='sigmoid', padding='same')(v2_upsample_back)\n",
    "    decoder = Model(latent_inputs, v1_conv2d_5x5_back, name='pulvinar_to_v1_decoder')\n",
    "    decoder.summary()\n",
    "    if do_plot_model: \n",
    "        plot_model(decoder, to_file='data\\{}.png'.format(decoder.name), show_shapes=True)\n",
    "        \n",
    "    return decoder\n",
    "\n",
    "def create_autoencoder(retina, encoder, prob_model, decoder):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    autoencoder_output = decoder(encoder(retina)[2])\n",
    "    autoencoder = Model(retina, autoencoder_output, name='v1_to_pulvinar_vae')\n",
    "\n",
    "    # now compile with the optimizer VAE loss function\n",
    "    optimizer = 'adadelta'\n",
    "    [z_mean, z_log_var, z] = prob_model\n",
    "    autoencoder.compile(optimizer=optimizer, \n",
    "                        loss=lambda y_true, y_pred: vae_loss(z_mean, z_log_var, y_true, y_pred))\n",
    "    autoencoder.summary()\n",
    "    if do_plot_model: \n",
    "        plot_model(autoencoder, to_file='data\\{}.png'.format(autoencoder.name), show_shapes=True)\n",
    "        \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina, encoder, latent_shape, [z_mean, z_log_var, z] = create_encoder()\n",
    "decoder = create_decoder(latent_shape)\n",
    "autoencoder = create_autoencoder(retina, encoder, [z_mean, z_log_var, z], decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train, \n",
    "                epochs=16, batch_size=128, \n",
    "                shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load show_original_decoded.py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def decode_latent(decoder, latent_vector:tuple):\n",
    "    \"\"\"\n",
    "    helper to decode latent, with caching to speed up\n",
    "    # Arguments\n",
    "        decode_only: model for decoding\n",
    "        latent_vector: _tuple_ representing the vector to be decoded\n",
    "    # Returns\n",
    "        decoded image\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    latent_vector_arr = np.array([latent_vector])\n",
    "    return decoder.predict(latent_vector_arr)\n",
    "\n",
    "def show_grayscale(rows, columns, at, pixel_array, sz):\n",
    "    import scipy\n",
    "    ax = plt.subplot(rows, columns, at)\n",
    "    interp_array = scipy.ndimage.zoom(pixel_array.reshape(sz,sz), 4.0, order=5)\n",
    "    plt.imshow(interp_array.reshape(sz*4, sz*4), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "def show_original_decoded(original, decoded, sz, n=10):\n",
    "    plt.figure(figsize=(n*2, 4))\n",
    "    for i in range(n):\n",
    "        show_grayscale(2, n, i+1, original[i], sz)\n",
    "        show_grayscale(2, n, i+1+n, decoded[i], sz)\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_only_imgs = encoder.predict(x_test[:10])\n",
    "decoded_imgs = \\\n",
    "    [decode_latent(decoder, tuple(latent_vector)) \n",
    "         for latent_vector in encode_only_imgs[2]]\n",
    "show_original_decoded(x_test[:10], decoded_imgs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model coefficients\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "timelabel = today.strftime('%Y%m%d%H%M')\n",
    "\n",
    "weights_dir = source_path / 'weights'\n",
    "autoencoder.save_weights(weights_dir / f\"{timelabel}_autoencoder.h5\")\n",
    "encoder.save_weights(weights_dir / f\"{timelabel}_encoder.h5\")\n",
    "decoder.save_weights(weights_dir / f\"{timelabel}_decoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
