{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-02 21:39:49,093 | INFO : Start with tf version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from common.filter_banks import make_gauss_kernels, make_dog_kernels\n",
    "from common.filter_banks import wave_numbers, make_sine_kernels, make_gabor_kernels, conv2d_sq\n",
    "from common.filter_banks import show_filter_bank, show_filter_response\n",
    "from common.image_ops import resize_img, whiten_img\n",
    "from imageio import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_uint\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import reprlib, os, logging, sys\n",
    "log_format = '%(asctime)s | %(levelname)s : %(message)s'\n",
    "logging.basicConfig(format=log_format, level=logging.INFO, stream=sys.stdout)\n",
    "logging.info(f\"Start with tf version {tf.version.VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "gauss_kernels_tf = make_gauss_kernels()\n",
    "show_filter_bank(gauss_kernels_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "dog_kernels_tf = make_dog_kernels()\n",
    "show_filter_bank(dog_kernels_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "ks = wave_numbers(6)\n",
    "freqs=[0.5,1.0,2.0]\n",
    "xs, ys = grid_for_sz(3)\n",
    "sine_kernels = []\n",
    "for freq in freqs:\n",
    "    for k in ks:\n",
    "        logging.info(f\"k={k} freq={freq}\")\n",
    "        sine_kernels \\\n",
    "            .append(np.exp(freq * (xs*k[0] + ys*k[1]) * 1.0j))\n",
    "sine_kernels = \\\n",
    "    tf.constant(sine_kernels, tf.complex64)\n",
    "sine_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "ks = wave_numbers(6)\n",
    "gabor_kernels = \\\n",
    "    make_gabor_kernels(sz=13, ks=ks, freqs=[0.5,1.0,2.0])\n",
    "logging.info(f\"{gabor_kernels.shape}\")\n",
    "show_filter_bank(gabor_kernels, rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One size to rule them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racoon_path = (Path(os.environ['DATA_ALL']) / 'Misc' / 'racoon').with_suffix('.png')\n",
    "racoon = imread(racoon_path)\n",
    "racoon = rgb2gray(racoon)\n",
    "racoon = resize_img(racoon, sz=sz)\n",
    "racoon = whiten_img(racoon)\n",
    "racoon = np.reshape(racoon, (1,sz,sz,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "racoon_in_tf = tf.constant(racoon, dtype=tf.float32)\n",
    "racoon_out_sq = conv2d_sq(racoon_in_tf, gabor_kernels)\n",
    "\n",
    "# add up the even and odd components\n",
    "racoon_out_sub = \\\n",
    "    tf.nn.max_pool(racoon_out_sq, (4,4), \n",
    "                   strides=2, padding='SAME')\n",
    "\n",
    "logging.info(racoon_out_sub.shape)\n",
    "show_filter_response(racoon_out_sub, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "def mse_tf(current_tf:tf.Tensor, kernel_tf:tf.Tensor, match_tf_sub:tf.Tensor):\n",
    "    current_out_tf_sq = conv2d_sq(current_tf, kernel_tf)    \n",
    "    current_out_tf_sub = tf.nn.max_pool(current_out_tf_sq, (4,4), strides=2, padding='SAME')    \n",
    "    loss_per_level = \\\n",
    "        tf.reduce_mean((current_out_tf_sub - match_tf_sub) ** 2, axis=[0,1,2])\n",
    "    \n",
    "    # print(loss_per_level.shape)\n",
    "    loss = tf.tensordot(loss_per_level, \n",
    "                        [8.] * 6 + [3.] * 6 + [1.] * 6, 1)\n",
    "    return loss\n",
    "\n",
    "current_value = tf.Variable(0.5 * np.ones((1,sz,sz,1)), dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    current_out = mse_tf(current_value, gabor_kernels, racoon_out_sub)\n",
    "grad = tape.gradient(current_out, current_value)\n",
    "logging.info(f\"Gradient max = {np.max(grad)}\")\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(5,3))\n",
    "axs[0].imshow(tf.reshape(current_value, (sz,sz)))\n",
    "axs[1].imshow(tf.reshape(grad, (sz,sz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "learning_rate = 1e+3\n",
    "optimizer = tf.optimizers.Adam()\n",
    "for n in range(1000):\n",
    "    optimizer.apply_gradients(zip([grad], [current_value]))\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_out = mse_tf(current_value, gabor_kernels, racoon_out_sub)\n",
    "        # tf.print(f\"loss = {current_out}   \")\n",
    "    grad = tape.gradient(current_out, current_value)\n",
    "    \n",
    "fig, axs = plt.subplots(1,3,figsize=(5,3))\n",
    "axs[0].imshow(tf.reshape(racoon[...,0], (sz,sz)), cmap='gray', vmin=0., vmax=0.8)\n",
    "axs[1].imshow(tf.reshape(current_value, (sz,sz)), cmap='gray', vmin=0., vmax=0.8)\n",
    "axs[2].imshow(tf.reshape(grad, (sz,sz)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))\n",
    "slice_path = Path(os.environ['DATA_ALL']) / 'NIH_DeepLesion' \\\n",
    "                    / 'Images_png_01' / 'Images_png' \\\n",
    "                    / '000001_01_01' / '108.png'\n",
    "transverse_slice = imread(slice_path)\n",
    "transverse_slice = resize(transverse_slice, (sz,sz))\n",
    "transverse_slice = img_as_uint(transverse_slice)\n",
    "logging.info(np.histogram(transverse_slice, 10))\n",
    "\n",
    "transverse_slice = clahe.apply(transverse_slice)\n",
    "ts_min, ts_max = np.min(transverse_slice), np.max(transverse_slice)\n",
    "ts_width = ts_max - ts_min\n",
    "transverse_slice = (transverse_slice - ts_min) / ts_width\n",
    "transverse_slice = np.reshape(transverse_slice, (1,sz,sz,1))\n",
    "logging.info(np.histogram(transverse_slice, 10))\n",
    "\n",
    "transverse_slice_tf = tf.constant(transverse_slice, dtype=tf.float32)\n",
    "transverse_slice_out_tf_sq = conv2d_sq(transverse_slice_tf, gabor_kernels)\n",
    "transverse_slice_out_sub = \\\n",
    "    tf.nn.max_pool(transverse_slice_out_tf_sq, (2,2), \n",
    "                   strides=2, padding='SAME')\n",
    "\n",
    "show_filter_response(transverse_slice_out_sub, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))\n",
    "cxr_image_path = Path(os.environ['DATA_ALL']) / 'NIH_Cxr8' \\\n",
    "                        / 'images' / '00010827_000.png'\n",
    "\n",
    "cxr_image = imread(cxr_image_path)\n",
    "cxr_image = resize(cxr_image, (sz,sz))\n",
    "cxr_image = img_as_uint(cxr_image)\n",
    "logging.info(np.histogram(cxr_image, 10))\n",
    "\n",
    "cxr_image = clahe.apply(cxr_image)\n",
    "cx_min, cx_max = np.min(cxr_image), np.max(cxr_image)\n",
    "cx_width = cx_max - cx_min\n",
    "cxr_image = (cxr_image - cx_min) / cx_width\n",
    "cxr_image = np.reshape(cxr_image, (1,sz,sz,1))\n",
    "logging.info(np.histogram(cxr_image, 10))\n",
    "\n",
    "cxr_image_tf = tf.constant(cxr_image, dtype=tf.float32)\n",
    "cxr_image_out_tf_sq = conv2d_sq(cxr_image_tf, gabor_kernels)\n",
    "cxr_image_out_sub = \\\n",
    "    tf.nn.max_pool(cxr_image_out_tf_sq, (4,4), \n",
    "                   strides=2, padding='SAME')\n",
    "\n",
    "show_filter_response(cxr_image_out_sub, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_value = tf.Variable(0.5 * np.ones((1,sz,sz,1)), dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    current_out = mse_tf(current_value, gabor_kernels, cxr_image_out_sub)\n",
    "grad = tape.gradient(current_out, current_value)\n",
    "print(grad.shape, current_out)\n",
    "fig, axs = plt.subplots(1,2,figsize=(5,3))\n",
    "axs[0].imshow(tf.reshape(current_value, (sz,sz)))\n",
    "axs[1].imshow(tf.reshape(grad, (sz,sz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from IPython.display import clear_output\n",
    "learning_rate = 1e+3\n",
    "\n",
    "optimizer = tf.optimizers.Adam()\n",
    "for n in range(1000):\n",
    "    optimizer.apply_gradients(zip([grad], [current_value]))\n",
    "    # current_value.assign_sub(learning_rate * grad)\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_out = mse_tf(current_value, gabor_kernels, cxr_image_out_sub)\n",
    "        # tf.print(f\"loss = {current_out}   \")\n",
    "    grad = tape.gradient(current_out, current_value)\n",
    "    \n",
    "fig, axs = plt.subplots(1,3,figsize=(5,3))\n",
    "axs[0].imshow(tf.reshape(cxr_image[...,0], (sz,sz)), cmap='gray', vmin=0., vmax=0.8)\n",
    "axs[1].imshow(tf.reshape(current_value, (sz,sz)), cmap='gray', vmin=0., vmax=0.8)\n",
    "axs[2].imshow(tf.reshape(grad, (sz,sz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Lambda\n",
    "from tensorflow.keras.layers import LocallyConnected2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.layers import ActivityRegularization\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    instead of sampling from Q(z|X), sample eps = N(0,I) \n",
    "        then z = z_mean + sqrt(var)*eps    \n",
    "    # Arguments\n",
    "        args (tensor tuple): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"    \n",
    "    z_mean, z_log_var = args\n",
    "    \n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def sampling_mean_log_var(z_mean_log_var):\n",
    "    \"\"\" \"\"\"\n",
    "    batch, dim = K.shape(z_mean_log_var)[0], K.int_shape(z_mean_log_var)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean_log_var[...,0] + K.exp(0.5 * z_mean_log_var[...,1]) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(z_mean, z_log_var, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute VAE loss, using either mse or crossentropy.\n",
    "    # Arguments\n",
    "        z_mean: mean of Q(z|X)\n",
    "        z_log_var: log variance of Q(z|X)\n",
    "        y_true, y_pred: truth and predicated values\n",
    "    # Returns\n",
    "        loss value\n",
    "    \"\"\"\n",
    "    match_loss = mse(K.flatten(y_true), K.flatten(y_pred))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return match_loss + (1e-4 * kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"v1_to_pulvinar_encoder/z/add_16:0\", shape=(None, 8), dtype=float32)\n",
      "Model: \"v1_to_pulvinar_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "v2_conv2d (Conv2D)           (None, 64, 64, 64)        320       \n",
      "_________________________________________________________________\n",
      "v2_maxpool (MaxPooling2D)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "v4_conv2d (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "v4_maxpool (MaxPooling2D)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "pit_conv2d (Conv2D)          (None, 16, 16, 64)        4160      \n",
      "_________________________________________________________________\n",
      "pit_maxpool (MaxPooling2D)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "cit_conv2d (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "ait_local (LocallyConnected2 (None, 6, 6, 2)           41544     \n",
      "_________________________________________________________________\n",
      "pulvinar_flatten (Flatten)   (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "pulvinar_dense (Dense)       (None, 16)                1168      \n",
      "_________________________________________________________________\n",
      "pulinvar_reshape (Reshape)   (None, 8, 2)              0         \n",
      "_________________________________________________________________\n",
      "z (Lambda)                   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 121,048\n",
      "Trainable params: 121,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 8) for input Tensor(\"z_sampling_16:0\", shape=(None, None, 8), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "2020-10-02 21:55:54,817 | WARNING : Model was constructed with shape (None, None, 8) for input Tensor(\"z_sampling_16:0\", shape=(None, None, 8), dtype=float32), but it was called on an input with incompatible shape (None, 8).\n",
      "Model: \"pulvinar_to_v1_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pulvinar_dense_back (Dense)  multiple                  648       \n",
      "_________________________________________________________________\n",
      "pulvinar_antiflatten (Reshap (None, 6, 6, 2)           0         \n",
      "_________________________________________________________________\n",
      "ait_padding_back (ZeroPaddin (None, 8, 8, 2)           0         \n",
      "_________________________________________________________________\n",
      "ait_local_back (LocallyConne (None, 6, 6, 2)           1368      \n",
      "_________________________________________________________________\n",
      "cit_padding_back (ZeroPaddin (None, 8, 8, 2)           0         \n",
      "_________________________________________________________________\n",
      "cit_conv2d_trans (Conv2DTran (None, 8, 8, 64)          1216      \n",
      "_________________________________________________________________\n",
      "cit_upsample_back (UpSamplin (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "pit_conv2d_trans (Conv2DTran (None, 16, 16, 64)        4160      \n",
      "_________________________________________________________________\n",
      "pit_upsample_back (UpSamplin (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "v4_conv2d_trans (Conv2DTrans (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "v4_upsample_back (UpSampling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "v2_conv2d_trans (Conv2DTrans (None, 64, 64, 4)         260       \n",
      "=================================================================\n",
      "Total params: 44,580\n",
      "Trainable params: 44,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_func = 'softplus' # or 'relu'\n",
    "locally_connected_channels = 2\n",
    "latent_dim = 8\n",
    "\n",
    "# this is the V1 filter bank output\n",
    "v1_filtered_output = Input(shape=(sz//2,sz//2,4), name='v1_{}'.format(sz//2))\n",
    "\n",
    "encoder = \\\n",
    "    Sequential(name='v1_to_pulvinar_encoder', layers=\n",
    "    [\n",
    "        v1_filtered_output,\n",
    "        Conv2D(64, (1,1), name='v2_conv2d', activation=act_func, padding='same'),\n",
    "        MaxPooling2D((2,2), name='v2_maxpool', padding='same'),\n",
    "        Conv2D(64, (3,3), name='v4_conv2d', activation=act_func, padding='same'),\n",
    "        MaxPooling2D((2,2), name='v4_maxpool', padding='same'),\n",
    "        Conv2D(64, (1,1), name='pit_conv2d', activation=act_func, padding='same'),\n",
    "        MaxPooling2D((2,2), name='pit_maxpool', padding='same'),\n",
    "        Conv2D(64, (3,3), name='cit_conv2d', activation=act_func, padding='same'),\n",
    "        LocallyConnected2D(locally_connected_channels, (3,3), \n",
    "                           name='ait_local', activation=act_func,\n",
    "                           kernel_regularizer=L1L2(l1=0.01, l2=0.01)),\n",
    "        Flatten(name='pulvinar_flatten'),\n",
    "        Dense((latent_dim*2), activation=act_func, name='pulvinar_dense'),\n",
    "        Reshape((latent_dim,2), name='pulinvar_reshape'),\n",
    "        Lambda(sampling_mean_log_var, output_shape=(latent_dim,1), name='z')\n",
    "    ])\n",
    "encoder_output = encoder(v1_filtered_output)\n",
    "print(encoder_output)\n",
    "encoder.summary()\n",
    "\n",
    "local_shape = encoder.get_layer('ait_local').output_shape\n",
    "z_shape = encoder.get_layer('z').output_shape\n",
    "decoder = \\\n",
    "    Sequential(name='pulvinar_to_v1_decoder', layers=\n",
    "    [\n",
    "        Input(shape=z_shape, name='z_sampling'),\n",
    "        Dense(np.prod(local_shape[1:]), name='pulvinar_dense_back', activation=act_func),\n",
    "        Reshape(local_shape[1:], name='pulvinar_antiflatten'),\n",
    "        ZeroPadding2D(padding=(1,1), name='ait_padding_back'),\n",
    "        LocallyConnected2D(locally_connected_channels, (3,3), \n",
    "                           name='ait_local_back', activation=act_func,\n",
    "                           kernel_regularizer=L1L2(l1=0.01, l2=0.01)),\n",
    "        ZeroPadding2D(padding=(1,1), name='cit_padding_back'),\n",
    "        Conv2DTranspose(64, (3,3), name='cit_conv2d_trans', activation=act_func, padding='same'),       \n",
    "        UpSampling2D((2,2), name='cit_upsample_back'),\n",
    "        Conv2DTranspose(64, (1,1), name='pit_conv2d_trans', activation=act_func, padding='same'),\n",
    "        UpSampling2D((2,2), name='pit_upsample_back'),\n",
    "        Conv2DTranspose(64, (3,3), name='v4_conv2d_trans', activation=act_func, padding='same'),\n",
    "        UpSampling2D((2,2), name='v4_upsample_back'),\n",
    "        Conv2DTranspose(4, (1,1), name='v2_conv2d_trans', activation=act_func, padding='same')\n",
    "    ])\n",
    "decoder_output = decoder(encoder_output)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"v1_to_pulvinar_vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "v1_64 (InputLayer)           [(None, 64, 64, 4)]       0         \n",
      "_________________________________________________________________\n",
      "v1_to_pulvinar_encoder (Sequ (None, 8)                 121048    \n",
      "_________________________________________________________________\n",
      "pulvinar_to_v1_decoder (Sequ (None, 64, 64, 4)         44580     \n",
      "=================================================================\n",
      "Total params: 165,628\n",
      "Trainable params: 165,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Variable 'v2_conv2d/kernel:0' shape=(1, 1, 4, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.01920557, -0.26810384,  0.22631335,  0.09199455,\n",
      "           0.26641685,  0.00082761,  0.16940999, -0.08342358,\n",
      "           0.11300257,  0.04578683,  0.21995461, -0.07693768,\n",
      "          -0.19567347, -0.09900907, -0.27615213,  0.11148515,\n",
      "          -0.1818741 , -0.00957569, -0.18748233,  0.26495534,\n",
      "           0.20972252,  0.2307989 , -0.2221449 ,  0.06107712,\n",
      "           0.14366269,  0.2882703 , -0.18357097,  0.08695161,\n",
      "           0.22082198,  0.19788095,  0.03612608,  0.03719398,\n",
      "           0.1666246 ,  0.2226398 , -0.24037342,  0.04066825,\n",
      "          -0.09039512,  0.15380254, -0.09161593,  0.24345016,\n",
      "           0.15391049, -0.10706197,  0.1941914 , -0.18850513,\n",
      "           0.11463016, -0.03736538,  0.16557828, -0.09796084,\n",
      "          -0.0718642 ,  0.13551986, -0.14435561, -0.19971183,\n",
      "           0.06032211,  0.2620582 , -0.00474811, -0.0624752 ,\n",
      "          -0.15709932, -0.01184678, -0.22802743, -0.116532  ,\n",
      "           0.2470631 , -0.27413324,  0.242859  ,  0.18817863],\n",
      "         [ 0.2051695 , -0.11563817, -0.12463567, -0.14831853,\n",
      "          -0.26823124, -0.03997129, -0.17977533,  0.03659776,\n",
      "           0.12510464,  0.10251689, -0.11402033, -0.25660074,\n",
      "          -0.14346921, -0.28315192,  0.13166884, -0.06539641,\n",
      "          -0.11022653, -0.23535526,  0.16835728,  0.26508963,\n",
      "          -0.14391637,  0.25261766,  0.2924719 ,  0.03303689,\n",
      "           0.209499  ,  0.0202418 ,  0.25624353,  0.23503852,\n",
      "           0.0731239 ,  0.28565168,  0.2700354 , -0.0319961 ,\n",
      "           0.11503088,  0.05319306, -0.13560441,  0.21734983,\n",
      "          -0.16914645,  0.2301104 ,  0.06401095,  0.23092818,\n",
      "          -0.25804302,  0.06887466,  0.20558023, -0.04315731,\n",
      "          -0.18331608,  0.03998774,  0.2257719 , -0.04947107,\n",
      "          -0.23603499,  0.13937157,  0.00132895,  0.13320309,\n",
      "          -0.14039813, -0.03587142, -0.17683357, -0.1198052 ,\n",
      "          -0.01195195, -0.12815753,  0.29642868, -0.20382884,\n",
      "           0.18454766,  0.09366527, -0.10930699, -0.06338808],\n",
      "         [ 0.23409534, -0.05035265,  0.10291973,  0.04252517,\n",
      "          -0.21229371,  0.23447752, -0.13631277, -0.2688214 ,\n",
      "           0.16974518, -0.04879586,  0.06696367,  0.20236194,\n",
      "           0.22947818, -0.06682488,  0.2512446 , -0.15346119,\n",
      "           0.12408072, -0.29515663, -0.15093833, -0.19747168,\n",
      "          -0.19376513, -0.03840637, -0.28304166, -0.29457602,\n",
      "           0.20404112,  0.15143833, -0.28584397,  0.08225653,\n",
      "          -0.2838061 ,  0.24754006, -0.28686738,  0.04488203,\n",
      "          -0.13636956,  0.226722  ,  0.02133918,  0.0461556 ,\n",
      "          -0.03556547,  0.03661227, -0.12298909,  0.11767915,\n",
      "           0.09674889,  0.06934935, -0.11486487, -0.18574779,\n",
      "          -0.05435991, -0.28733686,  0.11402932,  0.08773127,\n",
      "          -0.18798232,  0.18269598, -0.22952315,  0.11701527,\n",
      "           0.02085561, -0.02549785,  0.26437604,  0.18818572,\n",
      "          -0.15437095,  0.01572061,  0.09008875,  0.2229582 ,\n",
      "           0.23617882,  0.22148287,  0.02256954, -0.2407351 ],\n",
      "         [-0.03218666,  0.11195627, -0.09461166,  0.05065519,\n",
      "          -0.21886581, -0.20111811, -0.03845602,  0.04706955,\n",
      "           0.02216014,  0.11923078, -0.15154116,  0.20903331,\n",
      "          -0.21559164,  0.22394991, -0.09766085, -0.03137961,\n",
      "          -0.22401726, -0.2360479 , -0.04912008,  0.15557498,\n",
      "          -0.09456308,  0.03457686, -0.20795885,  0.08203042,\n",
      "           0.2072702 ,  0.08781922, -0.18436706,  0.23711544,\n",
      "           0.1846694 , -0.2035598 , -0.19613487,  0.25378716,\n",
      "          -0.25430885, -0.0165337 , -0.19840667, -0.25046015,\n",
      "           0.29568148, -0.20310146, -0.15965696,  0.05325943,\n",
      "           0.257627  ,  0.20199034, -0.24516791, -0.19228667,\n",
      "           0.225084  , -0.24165243, -0.0376716 , -0.22682843,\n",
      "          -0.26348722,  0.20815545, -0.21159096,  0.27485067,\n",
      "           0.2661267 ,  0.2191478 , -0.29107782,  0.00230712,\n",
      "          -0.16724399, -0.00795466,  0.1989226 ,  0.10123277,\n",
      "           0.11100033,  0.00133064,  0.15670246, -0.25448984]]]],\n",
      "      dtype=float32)>,\n",
      " <tf.Variable 'v2_conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'v4_conv2d/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-0.05530318, -0.06357886,  0.06083566, ...,  0.01666036,\n",
      "          -0.05448897, -0.01882621],\n",
      "         [-0.03643642,  0.00114171,  0.0622873 , ...,  0.06518438,\n",
      "           0.06991768,  0.06664918],\n",
      "         [-0.01206817,  0.04238662,  0.065035  , ..., -0.00773855,\n",
      "           0.04859839, -0.03238979],\n",
      "         ...,\n",
      "         [-0.05142315,  0.02898404, -0.0095037 , ..., -0.02835992,\n",
      "           0.02686327, -0.0113782 ],\n",
      "         [ 0.00409973,  0.03984041, -0.03716018, ...,  0.03601166,\n",
      "          -0.06666928, -0.03006915],\n",
      "         [ 0.00511073,  0.06252129, -0.05643744, ..., -0.02171049,\n",
      "           0.02767342, -0.05056483]],\n",
      "\n",
      "        [[ 0.03799096, -0.00329311, -0.01328045, ...,  0.00777753,\n",
      "           0.02699476,  0.01878881],\n",
      "         [ 0.02324659,  0.03121431, -0.00452077, ...,  0.0412824 ,\n",
      "          -0.00907077, -0.00680351],\n",
      "         [-0.05222982, -0.06460341, -0.05430989, ..., -0.06602935,\n",
      "          -0.04262555,  0.0513672 ],\n",
      "         ...,\n",
      "         [ 0.03549337,  0.04157846,  0.00195809, ...,  0.03668099,\n",
      "           0.06343089,  0.0233141 ],\n",
      "         [-0.01030595, -0.03662002,  0.06990971, ...,  0.0257037 ,\n",
      "           0.01851989, -0.02013214],\n",
      "         [ 0.02927158, -0.03222822,  0.0696159 , ...,  0.03431252,\n",
      "           0.01928456,  0.01357585]],\n",
      "\n",
      "        [[-0.04638575,  0.03696264, -0.03288506, ...,  0.06267051,\n",
      "           0.06588461,  0.01346099],\n",
      "         [-0.04721181,  0.04303302,  0.02344336, ...,  0.01596377,\n",
      "          -0.06320404,  0.0478178 ],\n",
      "         [-0.02563694,  0.04678378,  0.01273707, ...,  0.04701842,\n",
      "          -0.06523079, -0.07208989],\n",
      "         ...,\n",
      "         [ 0.05171682, -0.03113462,  0.062663  , ..., -0.01463944,\n",
      "           0.01722957,  0.01172995],\n",
      "         [ 0.02642667, -0.02689266, -0.02474694, ..., -0.01489255,\n",
      "          -0.02178992, -0.01244959],\n",
      "         [ 0.00901417, -0.00819841, -0.03898914, ...,  0.00607046,\n",
      "          -0.06099981, -0.03183736]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03915067,  0.01775844, -0.07016305, ..., -0.02697501,\n",
      "           0.0413227 ,  0.04916647],\n",
      "         [-0.00769394,  0.06415056, -0.00986612, ..., -0.06914454,\n",
      "           0.01178556,  0.01731361],\n",
      "         [ 0.01146235,  0.03648086, -0.04171666, ..., -0.0492871 ,\n",
      "          -0.01302249,  0.05478953],\n",
      "         ...,\n",
      "         [ 0.03510036,  0.02598912, -0.02429372, ...,  0.05940583,\n",
      "          -0.01612195,  0.06480747],\n",
      "         [ 0.05003919, -0.04076752, -0.02658559, ..., -0.01784157,\n",
      "          -0.03609182,  0.00069731],\n",
      "         [-0.051863  ,  0.04897521, -0.06079581, ..., -0.02250544,\n",
      "           0.07080105,  0.07132369]],\n",
      "\n",
      "        [[-0.03789498, -0.01602953, -0.06767181, ...,  0.03078023,\n",
      "          -0.04780188, -0.06310692],\n",
      "         [ 0.05450121,  0.01419872,  0.06599095, ...,  0.02576549,\n",
      "          -0.03074092,  0.06934699],\n",
      "         [ 0.0305762 ,  0.0513285 , -0.06866777, ..., -0.04949287,\n",
      "           0.0014176 , -0.04137785],\n",
      "         ...,\n",
      "         [ 0.01907425, -0.03990329,  0.04458246, ..., -0.07214032,\n",
      "          -0.03903155, -0.05453101],\n",
      "         [-0.06340744, -0.05440339, -0.03369038, ..., -0.04554275,\n",
      "          -0.02300102, -0.06048646],\n",
      "         [ 0.05637765,  0.01417683,  0.02712648, ..., -0.06226565,\n",
      "           0.04713259, -0.05786894]],\n",
      "\n",
      "        [[-0.00784843,  0.0328479 ,  0.04164071, ..., -0.02382566,\n",
      "           0.02955519,  0.0284802 ],\n",
      "         [-0.00347298, -0.05677026, -0.01523146, ..., -0.07017957,\n",
      "           0.00731674, -0.00142059],\n",
      "         [-0.04062481,  0.01808846,  0.04129869, ...,  0.04747995,\n",
      "           0.00362707,  0.00367029],\n",
      "         ...,\n",
      "         [ 0.01876073,  0.03018716,  0.04798899, ...,  0.06512596,\n",
      "          -0.02022725,  0.05176438],\n",
      "         [-0.00528552, -0.0704738 , -0.03513623, ...,  0.05398512,\n",
      "          -0.02492684, -0.06215667],\n",
      "         [-0.04448551, -0.02271874,  0.02563466, ..., -0.02202685,\n",
      "           0.00781886,  0.01512845]]],\n",
      "\n",
      "\n",
      "       [[[-0.05590977, -0.01757706,  0.01990291, ..., -0.06110279,\n",
      "           0.0286033 ,  0.01126441],\n",
      "         [-0.0350697 , -0.01002173, -0.00711102, ..., -0.06193056,\n",
      "           0.0205641 , -0.03494221],\n",
      "         [-0.06194688, -0.04964069,  0.04625987, ...,  0.028731  ,\n",
      "          -0.0182458 , -0.05885705],\n",
      "         ...,\n",
      "         [ 0.070952  , -0.04360059,  0.024822  , ...,  0.02501019,\n",
      "           0.03858382, -0.01646009],\n",
      "         [-0.00477744, -0.01359892,  0.01764175, ..., -0.01002122,\n",
      "           0.05549076, -0.04037086],\n",
      "         [ 0.06445998,  0.02884983,  0.02148507, ...,  0.06425613,\n",
      "           0.0571699 ,  0.02522723]],\n",
      "\n",
      "        [[-0.03933432, -0.0179196 ,  0.0633706 , ...,  0.0399151 ,\n",
      "           0.03972163, -0.06939282],\n",
      "         [-0.06247533,  0.04723222, -0.05928824, ..., -0.05751093,\n",
      "           0.01671249,  0.06371108],\n",
      "         [-0.00979941, -0.01044534,  0.03363241, ..., -0.06701527,\n",
      "          -0.06699197,  0.06816959],\n",
      "         ...,\n",
      "         [ 0.03201059,  0.0004193 ,  0.05398768, ...,  0.00408579,\n",
      "          -0.00123326, -0.03416309],\n",
      "         [ 0.06593314, -0.02283464,  0.05162125, ..., -0.05824626,\n",
      "           0.00863972,  0.06917073],\n",
      "         [-0.06997992,  0.06866138,  0.05771406, ...,  0.06278524,\n",
      "           0.00365899,  0.03832996]],\n",
      "\n",
      "        [[-0.05316059,  0.01219927, -0.00531512, ...,  0.04105752,\n",
      "           0.06392407,  0.03378171],\n",
      "         [-0.0374911 , -0.05204833, -0.05689678, ..., -0.01915662,\n",
      "          -0.00527926, -0.06065506],\n",
      "         [ 0.06654519, -0.02632036,  0.01544087, ...,  0.03380702,\n",
      "           0.03520387,  0.06455906],\n",
      "         ...,\n",
      "         [-0.02393192,  0.01744846,  0.00925472, ...,  0.02401234,\n",
      "          -0.03076867, -0.03422538],\n",
      "         [ 0.05931152, -0.02720745,  0.05496772, ...,  0.01160081,\n",
      "          -0.06907976,  0.02575897],\n",
      "         [ 0.0706379 , -0.00072045, -0.01252292, ..., -0.06505834,\n",
      "           0.05132501, -0.0655011 ]]]], dtype=float32)>,\n",
      " <tf.Variable 'v4_conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'pit_conv2d/kernel:0' shape=(1, 1, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-0.10144198,  0.11299811, -0.11949438, ..., -0.07217698,\n",
      "          -0.07010292, -0.03083676],\n",
      "         [ 0.18093906, -0.17487288, -0.10201506, ...,  0.14146756,\n",
      "          -0.1298023 , -0.18549621],\n",
      "         [ 0.06124099, -0.0543392 , -0.09536532, ...,  0.17811517,\n",
      "           0.03833176, -0.11957924],\n",
      "         ...,\n",
      "         [-0.04496719,  0.11980553, -0.12226467, ...,  0.06046309,\n",
      "           0.04740609, -0.10076603],\n",
      "         [ 0.1570187 , -0.08905859, -0.11104205, ...,  0.1543601 ,\n",
      "           0.03254333,  0.21433707],\n",
      "         [ 0.04863591,  0.20956491,  0.08256672, ...,  0.02025886,\n",
      "          -0.16967484,  0.09623154]]]], dtype=float32)>,\n",
      " <tf.Variable 'pit_conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'cit_conv2d/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.02145512, -0.04421712,  0.01069913, ...,  0.03663966,\n",
      "           0.02686804,  0.07158129],\n",
      "         [ 0.03831258,  0.07073766,  0.04266682, ...,  0.02296092,\n",
      "          -0.04507593, -0.02983347],\n",
      "         [-0.00156488, -0.006408  , -0.06337842, ...,  0.03700521,\n",
      "          -0.03296312, -0.05929217],\n",
      "         ...,\n",
      "         [-0.02495437,  0.0449933 , -0.04667748, ..., -0.02529331,\n",
      "          -0.0469237 ,  0.02837724],\n",
      "         [ 0.01998798,  0.06905653, -0.04536119, ...,  0.05804323,\n",
      "           0.05476564,  0.01297261],\n",
      "         [ 0.02457777,  0.06889969, -0.02073783, ...,  0.03864787,\n",
      "          -0.01993793, -0.01649422]],\n",
      "\n",
      "        [[ 0.02509727, -0.05476859, -0.01192607, ..., -0.03225771,\n",
      "          -0.06510852,  0.04946233],\n",
      "         [-0.02144238, -0.03286494,  0.00298412, ..., -0.02509012,\n",
      "          -0.06610964,  0.03352211],\n",
      "         [-0.02348096, -0.00314075,  0.00287926, ...,  0.04618445,\n",
      "           0.04214679, -0.0189261 ],\n",
      "         ...,\n",
      "         [-0.06459992, -0.00084367, -0.06919838, ...,  0.0248782 ,\n",
      "           0.002977  , -0.04947864],\n",
      "         [-0.00781039,  0.01578878, -0.05814959, ..., -0.03182955,\n",
      "          -0.01352629, -0.06093064],\n",
      "         [ 0.05549875, -0.01260981, -0.04375883, ...,  0.00352273,\n",
      "          -0.06550069,  0.03317103]],\n",
      "\n",
      "        [[ 0.04792888,  0.03099247,  0.0437476 , ..., -0.00729001,\n",
      "          -0.03105922, -0.0266423 ],\n",
      "         [-0.02282846,  0.04342934, -0.03536071, ..., -0.03157875,\n",
      "          -0.03263501,  0.00763285],\n",
      "         [ 0.01368922, -0.01966474,  0.07127033, ..., -0.05503821,\n",
      "          -0.00455957, -0.00891069],\n",
      "         ...,\n",
      "         [-0.06341581, -0.03216538,  0.01755994, ...,  0.02482007,\n",
      "          -0.00881216,  0.01697944],\n",
      "         [-0.02693932, -0.01994579,  0.0208074 , ..., -0.02616488,\n",
      "          -0.03978989,  0.01428804],\n",
      "         [-0.00597242,  0.06553277,  0.06232147, ...,  0.02773021,\n",
      "          -0.01123803, -0.00046822]]],\n",
      "\n",
      "\n",
      "       [[[-0.0015452 ,  0.05250867, -0.0105008 , ...,  0.00625344,\n",
      "           0.01811412,  0.00360303],\n",
      "         [ 0.0259111 ,  0.01894761,  0.01903717, ...,  0.05501834,\n",
      "          -0.00059327, -0.06298407],\n",
      "         [ 0.04477154, -0.02615614, -0.01991236, ..., -0.01942848,\n",
      "           0.04463391,  0.0489045 ],\n",
      "         ...,\n",
      "         [ 0.03309559,  0.07083279,  0.03369907, ..., -0.02172612,\n",
      "           0.05167709, -0.06647247],\n",
      "         [ 0.0250799 , -0.06958929, -0.06019975, ...,  0.01371334,\n",
      "          -0.01032104, -0.06206009],\n",
      "         [-0.03321905,  0.00637551, -0.03352608, ..., -0.01802403,\n",
      "          -0.0573651 ,  0.00455878]],\n",
      "\n",
      "        [[ 0.03319601, -0.04361791,  0.05418667, ..., -0.04788112,\n",
      "          -0.04057797, -0.02650557],\n",
      "         [ 0.03320776, -0.04608233,  0.04000899, ...,  0.07161593,\n",
      "           0.00046627,  0.05240877],\n",
      "         [ 0.04552842,  0.03776225,  0.04553995, ...,  0.00050986,\n",
      "          -0.02081082,  0.04549356],\n",
      "         ...,\n",
      "         [ 0.05118977, -0.04767197, -0.02965248, ..., -0.05560888,\n",
      "          -0.04404337, -0.03720786],\n",
      "         [ 0.04097217, -0.00188387,  0.06152381, ..., -0.06982018,\n",
      "           0.05567783,  0.04238982],\n",
      "         [-0.01790955, -0.0139893 , -0.0568373 , ...,  0.04509071,\n",
      "          -0.03843372,  0.03377182]],\n",
      "\n",
      "        [[-0.02715122,  0.01508263,  0.00448242, ..., -0.00519266,\n",
      "          -0.02303282,  0.07161018],\n",
      "         [-0.07215676,  0.06891942,  0.03087334, ...,  0.02983522,\n",
      "           0.00837787, -0.06459004],\n",
      "         [-0.0617752 ,  0.02428842,  0.04323956, ..., -0.01221216,\n",
      "           0.05845489, -0.05537567],\n",
      "         ...,\n",
      "         [ 0.04985918, -0.00493284, -0.06863877, ..., -0.00143797,\n",
      "          -0.07108954,  0.04178715],\n",
      "         [ 0.06566423,  0.03390233,  0.06048301, ..., -0.01480736,\n",
      "          -0.05045939,  0.06610374],\n",
      "         [-0.06421794, -0.01569635,  0.00997153, ..., -0.04508133,\n",
      "           0.04740465, -0.05075382]]],\n",
      "\n",
      "\n",
      "       [[[-0.05110334,  0.05977778,  0.02248316, ...,  0.05551049,\n",
      "          -0.0202444 , -0.0564054 ],\n",
      "         [-0.01617406,  0.04800224,  0.00844385, ...,  0.00759223,\n",
      "           0.06787644,  0.0053065 ],\n",
      "         [ 0.04898272,  0.06495279,  0.04636293, ...,  0.01599138,\n",
      "           0.03578355,  0.04811086],\n",
      "         ...,\n",
      "         [-0.06382573, -0.04227237,  0.04514274, ...,  0.04937313,\n",
      "           0.00584165,  0.03820378],\n",
      "         [-0.0669748 , -0.0580537 , -0.06999826, ...,  0.06458753,\n",
      "          -0.05990311, -0.02925618],\n",
      "         [-0.009873  , -0.02883015,  0.00940149, ...,  0.06027186,\n",
      "          -0.01608282, -0.0055695 ]],\n",
      "\n",
      "        [[ 0.05449343, -0.01325309, -0.06557342, ..., -0.02621306,\n",
      "           0.00514404, -0.00041185],\n",
      "         [ 0.02944901, -0.03521633, -0.00271074, ...,  0.03315098,\n",
      "          -0.03096025, -0.06083246],\n",
      "         [-0.01962627, -0.03450466, -0.00160284, ...,  0.03077079,\n",
      "          -0.03162477, -0.03827659],\n",
      "         ...,\n",
      "         [ 0.0582678 ,  0.00610168, -0.05080223, ...,  0.04517258,\n",
      "           0.01198485,  0.0705211 ],\n",
      "         [-0.02469384,  0.04186417, -0.00912412, ...,  0.04120097,\n",
      "          -0.03807913, -0.03477239],\n",
      "         [ 0.04196712,  0.02509669, -0.04808412, ..., -0.057494  ,\n",
      "          -0.00572526, -0.02222935]],\n",
      "\n",
      "        [[-0.02841881,  0.04273373,  0.03599249, ...,  0.02145246,\n",
      "           0.07180254, -0.03595249],\n",
      "         [ 0.03659026,  0.06853907, -0.03077504, ...,  0.01444684,\n",
      "          -0.04102284,  0.06364906],\n",
      "         [ 0.05523373,  0.02457836, -0.03935968, ...,  0.04781   ,\n",
      "          -0.04688232, -0.01536657],\n",
      "         ...,\n",
      "         [ 0.01719196, -0.03395617, -0.04267585, ..., -0.05943035,\n",
      "           0.00506019,  0.00735638],\n",
      "         [-0.06725056, -0.03656767,  0.06416741, ..., -0.02865629,\n",
      "           0.01743665,  0.00461819],\n",
      "         [-0.01298701,  0.04975037, -0.00839788, ..., -0.02716701,\n",
      "          -0.05665983, -0.06217841]]]], dtype=float32)>,\n",
      " <tf.Variable 'cit_conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'ait_local/kernel:0' shape=(36, 576, 2) dtype=float32, numpy=\n",
      "array([[[ 1.40982550e-02,  4.70563769e-04],\n",
      "        [-5.43895271e-03,  1.19252186e-02],\n",
      "        [ 1.59809366e-04, -6.84903376e-03],\n",
      "        ...,\n",
      "        [-1.69729721e-02,  5.53617068e-03],\n",
      "        [-5.50381839e-04, -1.61869023e-02],\n",
      "        [ 1.30780861e-02, -6.55147620e-03]],\n",
      "\n",
      "       [[ 7.73100182e-04, -5.02408855e-03],\n",
      "        [-2.63244659e-03,  1.55910775e-02],\n",
      "        [ 1.03378147e-02, -1.59997940e-02],\n",
      "        ...,\n",
      "        [-4.63567767e-03,  6.44413382e-03],\n",
      "        [-1.62909552e-02, -9.64988396e-03],\n",
      "        [-3.20067350e-03,  1.23773385e-02]],\n",
      "\n",
      "       [[-2.87551805e-03, -1.32971630e-03],\n",
      "        [-1.60994194e-03, -1.32302009e-03],\n",
      "        [-9.77207348e-03, -1.25847533e-02],\n",
      "        ...,\n",
      "        [ 5.57438843e-03, -5.65240905e-03],\n",
      "        [ 1.47715062e-02,  8.20449926e-03],\n",
      "        [-7.19793048e-03, -1.64785124e-02]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 7.32636265e-03,  1.61547847e-02],\n",
      "        [ 7.00121745e-04,  2.64039822e-03],\n",
      "        [ 1.46242641e-02,  3.46596725e-03],\n",
      "        ...,\n",
      "        [-8.70595407e-03,  6.93233684e-03],\n",
      "        [-5.76141663e-03,  1.22530386e-04],\n",
      "        [ 6.21515885e-03, -6.48326613e-03]],\n",
      "\n",
      "       [[ 1.18927173e-02,  1.04052275e-02],\n",
      "        [ 1.58103183e-03, -1.05542354e-02],\n",
      "        [ 1.23060998e-02, -6.20631222e-03],\n",
      "        ...,\n",
      "        [ 8.27964395e-05, -1.31596532e-02],\n",
      "        [ 6.44607469e-04,  1.16272811e-02],\n",
      "        [ 1.62084587e-02, -1.17307827e-02]],\n",
      "\n",
      "       [[ 1.55650452e-03,  1.77170150e-03],\n",
      "        [-1.68783199e-02, -1.40145021e-02],\n",
      "        [ 4.32747230e-03,  3.07423808e-03],\n",
      "        ...,\n",
      "        [-6.86294399e-03,  1.61258131e-02],\n",
      "        [ 4.18054312e-03, -1.55938901e-02],\n",
      "        [ 5.04490174e-03, -2.64052302e-03]]], dtype=float32)>,\n",
      " <tf.Variable 'ait_local/bias:0' shape=(6, 6, 2) dtype=float32, numpy=\n",
      "array([[[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]], dtype=float32)>,\n",
      " <tf.Variable 'pulvinar_dense/kernel:0' shape=(72, 16) dtype=float32, numpy=\n",
      "array([[ 0.00038052,  0.12549922,  0.24094269, ...,  0.21060482,\n",
      "         0.12692776,  0.03497654],\n",
      "       [ 0.22357509,  0.16171527,  0.15989766, ...,  0.06919384,\n",
      "        -0.21448821, -0.15221739],\n",
      "       [-0.04459788,  0.17950574, -0.18684828, ...,  0.20415512,\n",
      "        -0.11295806,  0.0614706 ],\n",
      "       ...,\n",
      "       [-0.16151592, -0.17476004, -0.04297252, ...,  0.0008857 ,\n",
      "         0.0979282 ,  0.12886927],\n",
      "       [ 0.1016607 ,  0.08123296, -0.1343322 , ..., -0.2194782 ,\n",
      "        -0.07792796,  0.14187789],\n",
      "       [-0.1428434 , -0.11663671, -0.01551551, ..., -0.2575878 ,\n",
      "         0.11933601,  0.02068996]], dtype=float32)>,\n",
      " <tf.Variable 'pulvinar_dense/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>,\n",
      " <tf.Variable 'pulvinar_dense_back/kernel:0' shape=(8, 72) dtype=float32, numpy=\n",
      "array([[-0.01300949, -0.26521328,  0.04210061,  0.07968941, -0.13435481,\n",
      "         0.02282363,  0.26646054,  0.15239316,  0.2482202 , -0.20481943,\n",
      "        -0.19088785, -0.05187486,  0.13668579,  0.16994831, -0.02530095,\n",
      "        -0.27291223, -0.23281844,  0.01527676,  0.1562851 ,  0.01051417,\n",
      "         0.16253999,  0.2411989 , -0.01438737,  0.06983441,  0.17542163,\n",
      "        -0.15748167, -0.09181131,  0.2605    , -0.05379769, -0.21618098,\n",
      "        -0.00551504, -0.2706196 , -0.16880482, -0.14469275, -0.04657446,\n",
      "         0.13476655, -0.11549553, -0.24704057, -0.14564623,  0.05382472,\n",
      "         0.0814805 , -0.08410726,  0.07179478,  0.04011118,  0.02413976,\n",
      "        -0.18886597, -0.18161865, -0.05959655, -0.13792212, -0.05352385,\n",
      "         0.11587259,  0.03657943, -0.2038137 , -0.23701069,  0.10916027,\n",
      "         0.13347623,  0.13827825, -0.0385474 , -0.11477463,  0.04878524,\n",
      "        -0.03232694,  0.25113428,  0.0011102 , -0.12507312,  0.06918734,\n",
      "         0.13397309, -0.26643166,  0.19171858,  0.18812051,  0.25629985,\n",
      "        -0.27193016,  0.01539272],\n",
      "       [-0.07191505, -0.23004378, -0.26199853, -0.20498396,  0.09528187,\n",
      "         0.15487438,  0.14924332, -0.24725975, -0.2333244 , -0.1397546 ,\n",
      "        -0.13880621,  0.08095816,  0.2581945 , -0.02582017,  0.05809799,\n",
      "         0.23484111, -0.02107123, -0.2729744 , -0.05108167,  0.05627665,\n",
      "         0.16611722,  0.03229487,  0.04419929,  0.23628038, -0.07478908,\n",
      "         0.18969214,  0.17343402, -0.08218534, -0.20612392,  0.23003197,\n",
      "         0.20061877, -0.1683893 ,  0.20156172,  0.00714594,  0.2245174 ,\n",
      "         0.06679872,  0.07415742, -0.10318345, -0.02893081, -0.26217288,\n",
      "         0.17591676, -0.00351509, -0.17937869,  0.03894183,  0.1499443 ,\n",
      "         0.04714903,  0.1674957 ,  0.2042385 , -0.11936183,  0.15363851,\n",
      "        -0.0456204 , -0.24168101, -0.2454171 ,  0.08041099, -0.01041472,\n",
      "        -0.11185052,  0.2738371 , -0.11555019,  0.15626192,  0.19824606,\n",
      "         0.18709737, -0.02976553,  0.1704543 ,  0.08580038,  0.10045254,\n",
      "         0.22551522, -0.0644495 , -0.26554614, -0.24697593,  0.05132973,\n",
      "         0.01606721, -0.17923078],\n",
      "       [-0.02135083,  0.21101794, -0.10621548,  0.0704934 , -0.25075388,\n",
      "         0.13233227,  0.03338659, -0.08644196,  0.11823356, -0.24941418,\n",
      "        -0.01514101,  0.23037887,  0.2561308 ,  0.08531681,  0.20722002,\n",
      "        -0.23845765, -0.19227384,  0.2587353 , -0.1107434 , -0.2726403 ,\n",
      "         0.26070547, -0.23460063, -0.19910917, -0.12668183, -0.02269894,\n",
      "         0.09506685, -0.24581246, -0.21651703,  0.06838062, -0.16067532,\n",
      "         0.00150934, -0.02039537,  0.03026894, -0.23056927,  0.00961176,\n",
      "        -0.064473  ,  0.1973998 ,  0.0702225 , -0.06369902, -0.05567247,\n",
      "         0.26881582,  0.20857099,  0.24964541,  0.0491924 , -0.03352278,\n",
      "         0.18771738, -0.01674578, -0.03052941,  0.03733608,  0.1300056 ,\n",
      "         0.19028434, -0.02541019, -0.01701942, -0.08806986,  0.22617209,\n",
      "        -0.23790619, -0.00711849,  0.15295368, -0.20098662,  0.11700702,\n",
      "        -0.2551582 ,  0.03184649,  0.08589029,  0.15799555, -0.24172735,\n",
      "        -0.18817183,  0.11883098,  0.0068171 ,  0.17125544, -0.06971863,\n",
      "         0.12937754,  0.18364763],\n",
      "       [ 0.08036116,  0.03261259, -0.01810846, -0.08757174, -0.25540495,\n",
      "        -0.17388533,  0.12469572,  0.24795192,  0.21227321, -0.21784061,\n",
      "         0.23368233, -0.26062816, -0.16331743,  0.16415396,  0.26981056,\n",
      "        -0.1149886 , -0.1811873 ,  0.16711459, -0.2729033 ,  0.21931186,\n",
      "        -0.17069182, -0.2056343 , -0.00088003,  0.15727419, -0.12282011,\n",
      "         0.16912177, -0.19283107,  0.23614353, -0.21247393, -0.22511032,\n",
      "        -0.2663991 ,  0.18369341,  0.18588844,  0.27139568, -0.0366623 ,\n",
      "         0.06651852,  0.17599809,  0.06723818, -0.10311396,  0.03187817,\n",
      "         0.08209491, -0.26729903, -0.07800524,  0.20000133,  0.00203043,\n",
      "        -0.1796947 , -0.25566533, -0.23827927, -0.08984461,  0.01258019,\n",
      "        -0.22631918,  0.0696229 ,  0.1313493 ,  0.16467783,  0.20741928,\n",
      "         0.05294764,  0.11531317,  0.02224416, -0.01509616, -0.12018225,\n",
      "         0.09656823,  0.26197308, -0.08956045,  0.18373317, -0.23456407,\n",
      "        -0.10457289, -0.07807191,  0.00173447,  0.03535238, -0.02063012,\n",
      "        -0.01916969,  0.1848397 ],\n",
      "       [ 0.1999079 , -0.10639967, -0.11569749,  0.07799017,  0.16207188,\n",
      "         0.118568  , -0.04542124,  0.1997928 ,  0.03887087,  0.00310576,\n",
      "         0.02647322,  0.19302621,  0.01117939,  0.12550688,  0.261764  ,\n",
      "        -0.26100615,  0.08256516, -0.19329849,  0.10803455, -0.11591087,\n",
      "        -0.24529801, -0.07760108, -0.01599216,  0.12305105,  0.16230205,\n",
      "         0.12265393, -0.14647357, -0.14932787, -0.1548335 ,  0.17318407,\n",
      "        -0.00402319, -0.02528645,  0.04714212, -0.04212673, -0.23194899,\n",
      "         0.06974357, -0.0624299 , -0.09845926, -0.16325358,  0.15838829,\n",
      "         0.14731011, -0.10650127, -0.04793786, -0.26016256, -0.04195762,\n",
      "         0.13309196,  0.09333298,  0.11459669, -0.16458347, -0.13713749,\n",
      "         0.12174335, -0.1157569 , -0.1933632 , -0.05475464,  0.26643878,\n",
      "        -0.18593135, -0.2512048 ,  0.02819452, -0.15426335,  0.06031263,\n",
      "        -0.2135721 , -0.2627064 ,  0.24151409,  0.12167153,  0.19939014,\n",
      "         0.08444646, -0.06546012,  0.03641856, -0.07927521,  0.08237842,\n",
      "        -0.10261297,  0.07834038],\n",
      "       [ 0.07165772, -0.03822406, -0.12789962,  0.18755913,  0.20979989,\n",
      "        -0.22684284, -0.1317172 ,  0.06091177, -0.04950151, -0.14166763,\n",
      "         0.21236038, -0.16381444,  0.05263358,  0.25346208, -0.25756872,\n",
      "         0.1406349 ,  0.21559632, -0.19673333, -0.2602259 ,  0.18913236,\n",
      "        -0.1246704 , -0.02565987,  0.20862696,  0.04811054,  0.06013015,\n",
      "         0.2558856 ,  0.1451163 ,  0.06549948,  0.18857586, -0.24165618,\n",
      "         0.18153742, -0.02131686, -0.0501229 ,  0.23682052,  0.1100091 ,\n",
      "         0.1527727 , -0.01692873,  0.17651796,  0.10250843, -0.08737069,\n",
      "         0.00778809, -0.20577362, -0.20171347,  0.02557564,  0.03079018,\n",
      "        -0.17359222, -0.1659775 ,  0.05311739,  0.12096995,  0.2213246 ,\n",
      "        -0.05558433,  0.10686451,  0.2453726 ,  0.09570411, -0.11628813,\n",
      "         0.07827073, -0.105674  , -0.2727018 , -0.00336236,  0.25264657,\n",
      "        -0.12813978,  0.04209256, -0.09654666, -0.06739967, -0.13814211,\n",
      "        -0.0376485 ,  0.18221569,  0.26750892, -0.11129957,  0.21016932,\n",
      "        -0.25820088, -0.24109963],\n",
      "       [ 0.04809102, -0.2567494 ,  0.26105177,  0.1817314 , -0.19136554,\n",
      "        -0.09730656, -0.02916464, -0.06140068, -0.20923667,  0.22239816,\n",
      "         0.19980839, -0.2564542 ,  0.18705845, -0.09573089, -0.19172609,\n",
      "         0.2293641 ,  0.05273706,  0.23035836, -0.12295932, -0.2203373 ,\n",
      "        -0.22424904,  0.27085882, -0.2627604 , -0.25272372, -0.00244531,\n",
      "         0.09005451, -0.10874593, -0.27114558,  0.13117725, -0.07094093,\n",
      "        -0.06485361,  0.06390679,  0.0988394 ,  0.26653582,  0.16881019,\n",
      "        -0.2736319 , -0.08962803,  0.19583529,  0.09639186, -0.08689229,\n",
      "        -0.15625441, -0.16772756, -0.14503632,  0.26066995,  0.09330046,\n",
      "         0.1015088 ,  0.05495372,  0.06390542,  0.11546281, -0.16941878,\n",
      "        -0.19304574,  0.20355403,  0.19897056, -0.13469851, -0.23879209,\n",
      "        -0.0408507 ,  0.01207194,  0.1552071 , -0.09322008, -0.2611272 ,\n",
      "         0.07752147,  0.03288475,  0.1517989 , -0.10106727, -0.12919903,\n",
      "        -0.02355081,  0.16155902, -0.19107231,  0.2539639 , -0.25345057,\n",
      "        -0.13899112,  0.21859539],\n",
      "       [ 0.07297999, -0.19590992, -0.16958405,  0.04537037,  0.10999671,\n",
      "        -0.0447655 ,  0.19229376, -0.19595686,  0.06833068, -0.12391104,\n",
      "        -0.12535512,  0.14504108, -0.09148498, -0.04658628, -0.0295216 ,\n",
      "        -0.20848808,  0.13573897, -0.04703569,  0.01487911,  0.1611419 ,\n",
      "         0.2679603 ,  0.00369379,  0.08209601, -0.04430459, -0.04271404,\n",
      "        -0.02860729, -0.09152442,  0.13443989,  0.2510376 , -0.15468913,\n",
      "         0.20107478, -0.12004402, -0.07540348,  0.09498641,  0.20996508,\n",
      "        -0.19319083, -0.17581248, -0.00371885, -0.24981548,  0.01329294,\n",
      "         0.2202709 ,  0.04585239, -0.0658178 , -0.07610983,  0.13323861,\n",
      "        -0.10614823,  0.02603126, -0.14694545,  0.25255907, -0.07375424,\n",
      "         0.10371265, -0.2449199 ,  0.1032334 , -0.18168595,  0.05542696,\n",
      "        -0.04064749, -0.16153602,  0.24047518, -0.06620897, -0.0952771 ,\n",
      "         0.03878218, -0.18864352, -0.26423126,  0.09885684, -0.06857449,\n",
      "        -0.23325023, -0.09176196,  0.2173441 ,  0.00156006, -0.1510577 ,\n",
      "        -0.11765786, -0.09270009]], dtype=float32)>,\n",
      " <tf.Variable 'pulvinar_dense_back/bias:0' shape=(72,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'ait_local_back/kernel:0' shape=(36, 18, 2) dtype=float32, numpy=\n",
      "array([[[ 0.0780127 , -0.02475875],\n",
      "        [-0.08767557,  0.05137198],\n",
      "        [ 0.05458936,  0.06278706],\n",
      "        ...,\n",
      "        [ 0.04195313, -0.05959742],\n",
      "        [ 0.02505503,  0.0677066 ],\n",
      "        [-0.0305731 , -0.02452724]],\n",
      "\n",
      "       [[ 0.07004866,  0.02687165],\n",
      "        [-0.03836176, -0.01616154],\n",
      "        [ 0.05905858, -0.01052753],\n",
      "        ...,\n",
      "        [-0.0854115 , -0.01575091],\n",
      "        [-0.01515388,  0.0001991 ],\n",
      "        [-0.032881  , -0.03809049]],\n",
      "\n",
      "       [[-0.03696437,  0.05724826],\n",
      "        [-0.01374848, -0.05684843],\n",
      "        [ 0.04917046,  0.04493053],\n",
      "        ...,\n",
      "        [-0.06629208, -0.08776119],\n",
      "        [-0.0634043 ,  0.06466702],\n",
      "        [ 0.05462995, -0.00946816]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.02686534, -0.02719368],\n",
      "        [ 0.08275859, -0.02799022],\n",
      "        [-0.09019843, -0.01215665],\n",
      "        ...,\n",
      "        [ 0.03905523, -0.08796595],\n",
      "        [-0.01469374, -0.01054331],\n",
      "        [-0.03139017, -0.05236892]],\n",
      "\n",
      "       [[-0.00633733, -0.01781726],\n",
      "        [ 0.01479177,  0.04057397],\n",
      "        [ 0.03673756,  0.00995824],\n",
      "        ...,\n",
      "        [-0.06248534, -0.03770062],\n",
      "        [ 0.0810508 , -0.07505919],\n",
      "        [ 0.09048982, -0.08258754]],\n",
      "\n",
      "       [[ 0.00477125, -0.08109084],\n",
      "        [-0.01813374, -0.01740149],\n",
      "        [-0.0541441 , -0.06034534],\n",
      "        ...,\n",
      "        [ 0.01176702,  0.07144739],\n",
      "        [-0.05463539, -0.00784124],\n",
      "        [-0.05298879, -0.00283194]]], dtype=float32)>,\n",
      " <tf.Variable 'ait_local_back/bias:0' shape=(6, 6, 2) dtype=float32, numpy=\n",
      "array([[[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]], dtype=float32)>,\n",
      " <tf.Variable 'cit_conv2d_trans/kernel:0' shape=(3, 3, 64, 2) dtype=float32, numpy=\n",
      "array([[[[-0.00513457, -0.03980862],\n",
      "         [ 0.03896824, -0.05859281],\n",
      "         [-0.05924647, -0.04325231],\n",
      "         ...,\n",
      "         [ 0.08859894, -0.01832808],\n",
      "         [-0.07092337, -0.04729426],\n",
      "         [-0.07717436, -0.06920911]],\n",
      "\n",
      "        [[-0.0723789 , -0.06582963],\n",
      "         [ 0.01438895,  0.01516031],\n",
      "         [-0.07890034, -0.01853703],\n",
      "         ...,\n",
      "         [ 0.02254234, -0.04167324],\n",
      "         [-0.00054135, -0.04539935],\n",
      "         [-0.05280988,  0.07618456]],\n",
      "\n",
      "        [[-0.07167988,  0.08665948],\n",
      "         [-0.05634767,  0.04893271],\n",
      "         [ 0.03236198, -0.00715174],\n",
      "         ...,\n",
      "         [ 0.08878463,  0.00117388],\n",
      "         [-0.03306998,  0.02894019],\n",
      "         [-0.08003973, -0.03121768]]],\n",
      "\n",
      "\n",
      "       [[[-0.01185022,  0.06747913],\n",
      "         [-0.01056102,  0.09412844],\n",
      "         [-0.0608356 ,  0.05832935],\n",
      "         ...,\n",
      "         [ 0.07366578, -0.08248992],\n",
      "         [ 0.08923171,  0.08260763],\n",
      "         [ 0.04030418,  0.05711745]],\n",
      "\n",
      "        [[ 0.0357855 ,  0.06704434],\n",
      "         [-0.07123912,  0.08334573],\n",
      "         [-0.04775503, -0.02140326],\n",
      "         ...,\n",
      "         [-0.02405209,  0.02382018],\n",
      "         [-0.06075485,  0.08663943],\n",
      "         [ 0.09142984, -0.04560887]],\n",
      "\n",
      "        [[-0.09893961, -0.09679138],\n",
      "         [-0.0578019 ,  0.0494303 ],\n",
      "         [ 0.04267582,  0.06065135],\n",
      "         ...,\n",
      "         [ 0.06742946,  0.09902436],\n",
      "         [ 0.00530463,  0.07557841],\n",
      "         [ 0.09453189, -0.06296138]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00894335, -0.07720843],\n",
      "         [ 0.06101353,  0.08826389],\n",
      "         [-0.00819564, -0.06335425],\n",
      "         ...,\n",
      "         [ 0.05259479, -0.04689865],\n",
      "         [-0.06689729,  0.07804061],\n",
      "         [ 0.03867631,  0.0136479 ]],\n",
      "\n",
      "        [[ 0.06619739,  0.02244731],\n",
      "         [-0.00677611,  0.05698293],\n",
      "         [-0.06981413, -0.04875216],\n",
      "         ...,\n",
      "         [-0.08668432,  0.06769361],\n",
      "         [ 0.04937793, -0.06475684],\n",
      "         [-0.00363613,  0.06586263]],\n",
      "\n",
      "        [[-0.10033959, -0.00770705],\n",
      "         [ 0.0162973 , -0.04553917],\n",
      "         [ 0.01635206, -0.03524374],\n",
      "         ...,\n",
      "         [ 0.0179824 , -0.02969686],\n",
      "         [-0.08162826, -0.01902698],\n",
      "         [ 0.02668158,  0.04062299]]]], dtype=float32)>,\n",
      " <tf.Variable 'cit_conv2d_trans/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'pit_conv2d_trans/kernel:0' shape=(1, 1, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.13307242,  0.2051778 , -0.1188718 , ...,  0.03319032,\n",
      "          -0.02085707,  0.00868358],\n",
      "         [-0.12819865, -0.12488001,  0.01994419, ..., -0.11872468,\n",
      "          -0.11122897, -0.09832594],\n",
      "         [ 0.10632648, -0.13315868,  0.08879001, ..., -0.09557232,\n",
      "          -0.20271759, -0.16475564],\n",
      "         ...,\n",
      "         [-0.11062951,  0.00068648,  0.19917749, ...,  0.1654766 ,\n",
      "          -0.18655826, -0.06383036],\n",
      "         [ 0.12807064, -0.08893307, -0.1368829 , ...,  0.1353363 ,\n",
      "           0.07020415, -0.03971194],\n",
      "         [-0.15194222,  0.05531393, -0.08364943, ...,  0.00031435,\n",
      "          -0.01510975,  0.11763303]]]], dtype=float32)>,\n",
      " <tf.Variable 'pit_conv2d_trans/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'v4_conv2d_trans/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.06545928, -0.05348233,  0.02618337, ...,  0.02327196,\n",
      "           0.02188216,  0.05132009],\n",
      "         [-0.02548301, -0.04752398,  0.06218483, ..., -0.0295332 ,\n",
      "           0.00521513,  0.02725084],\n",
      "         [ 0.01986833, -0.06674433, -0.0710813 , ...,  0.06080538,\n",
      "           0.00315235,  0.0608061 ],\n",
      "         ...,\n",
      "         [ 0.06107618,  0.01338555, -0.0234329 , ...,  0.06422785,\n",
      "          -0.03644351,  0.05479594],\n",
      "         [ 0.01599046,  0.0455206 ,  0.04337861, ...,  0.00433537,\n",
      "          -0.05044059,  0.06465259],\n",
      "         [-0.03425537,  0.00590508,  0.03812882, ..., -0.03068945,\n",
      "           0.02146725,  0.04747302]],\n",
      "\n",
      "        [[-0.06335624,  0.06575415, -0.04547074, ...,  0.02024861,\n",
      "          -0.06705825, -0.04130312],\n",
      "         [ 0.00233537,  0.06257482, -0.02055359, ..., -0.04944549,\n",
      "           0.06247792,  0.04414095],\n",
      "         [-0.06252741,  0.03887177, -0.03578598, ...,  0.00258068,\n",
      "           0.00463516,  0.04441272],\n",
      "         ...,\n",
      "         [-0.05313438, -0.04430784,  0.06436364, ...,  0.01819438,\n",
      "           0.04960658,  0.01221419],\n",
      "         [ 0.01378532, -0.03563985, -0.00094441, ..., -0.04246021,\n",
      "           0.00464681, -0.01423026],\n",
      "         [-0.04871564,  0.0686937 , -0.03743979, ..., -0.06411539,\n",
      "           0.0175557 , -0.00586715]],\n",
      "\n",
      "        [[-0.03114947,  0.01125786, -0.00072292, ...,  0.02152788,\n",
      "          -0.02639952, -0.00819142],\n",
      "         [ 0.038776  ,  0.00518335, -0.07187337, ...,  0.07057461,\n",
      "          -0.01464808,  0.06123808],\n",
      "         [ 0.0530014 ,  0.05381896, -0.03520305, ...,  0.0273054 ,\n",
      "          -0.02749008, -0.00482978],\n",
      "         ...,\n",
      "         [-0.0363354 ,  0.03957933, -0.0143958 , ..., -0.02116808,\n",
      "          -0.00654818,  0.00708111],\n",
      "         [ 0.05592743,  0.0352313 ,  0.01168515, ..., -0.06901939,\n",
      "          -0.02461362, -0.00507884],\n",
      "         [ 0.01393422,  0.00167199, -0.03359874, ...,  0.02466058,\n",
      "          -0.05799302,  0.05662438]]],\n",
      "\n",
      "\n",
      "       [[[-0.06674468,  0.05114933,  0.02245475, ...,  0.06741908,\n",
      "           0.02119827, -0.03188569],\n",
      "         [ 0.01905469,  0.03853912,  0.031571  , ...,  0.00379714,\n",
      "           0.05384378, -0.04117393],\n",
      "         [-0.03912811,  0.04845978,  0.02027678, ...,  0.00575898,\n",
      "          -0.00395235, -0.02354249],\n",
      "         ...,\n",
      "         [-0.05497068,  0.05350488,  0.05211274, ..., -0.01619022,\n",
      "           0.0024873 , -0.03341778],\n",
      "         [-0.01057015, -0.0461719 , -0.0445802 , ..., -0.01383905,\n",
      "          -0.03665265, -0.05404202],\n",
      "         [ 0.0517933 , -0.02985553,  0.04433927, ..., -0.0610148 ,\n",
      "           0.06661993,  0.06374104]],\n",
      "\n",
      "        [[ 0.03715835,  0.05020093,  0.02132577, ...,  0.01518764,\n",
      "          -0.04040104, -0.05774703],\n",
      "         [-0.05698075,  0.0597975 ,  0.02815543, ..., -0.05422661,\n",
      "          -0.00808515, -0.00493985],\n",
      "         [ 0.07160695, -0.02178109, -0.02005995, ...,  0.05126178,\n",
      "           0.01195741,  0.01741781],\n",
      "         ...,\n",
      "         [ 0.07203671, -0.03176027,  0.02740849, ...,  0.03362975,\n",
      "          -0.00539365, -0.00788333],\n",
      "         [ 0.05420527,  0.06353295,  0.03785579, ...,  0.02374201,\n",
      "           0.04918273,  0.05035548],\n",
      "         [ 0.01217298,  0.04399702, -0.05679913, ...,  0.0720046 ,\n",
      "          -0.02744503, -0.07000203]],\n",
      "\n",
      "        [[ 0.06397969,  0.02558917, -0.0461745 , ..., -0.04207937,\n",
      "          -0.03756963, -0.02028555],\n",
      "         [-0.00770097, -0.03368476,  0.04461531, ...,  0.03454741,\n",
      "          -0.07006793, -0.03957037],\n",
      "         [ 0.01924162, -0.02607071,  0.06941795, ..., -0.0321474 ,\n",
      "          -0.0623114 ,  0.03396018],\n",
      "         ...,\n",
      "         [-0.07152624,  0.02585319,  0.02871103, ...,  0.03117686,\n",
      "          -0.0637692 ,  0.06655699],\n",
      "         [-0.03831298,  0.01801601, -0.01412387, ...,  0.03597929,\n",
      "           0.05443767, -0.04220353],\n",
      "         [ 0.07027921,  0.05760822, -0.02748089, ...,  0.05597916,\n",
      "           0.02682818, -0.02968752]]],\n",
      "\n",
      "\n",
      "       [[[-0.03914477, -0.03337151, -0.00344721, ..., -0.04410136,\n",
      "          -0.00727193,  0.06365064],\n",
      "         [ 0.07017171,  0.00856283, -0.00371352, ..., -0.01676658,\n",
      "           0.04232076,  0.01399199],\n",
      "         [-0.020232  ,  0.00238611,  0.05471012, ...,  0.00249229,\n",
      "          -0.06762961,  0.00827635],\n",
      "         ...,\n",
      "         [-0.0291495 ,  0.02212445, -0.03420852, ..., -0.05156595,\n",
      "          -0.03760896, -0.01250045],\n",
      "         [-0.00119856, -0.04146113,  0.03806894, ...,  0.03139266,\n",
      "           0.02750641,  0.00836727],\n",
      "         [ 0.06102397,  0.064154  , -0.0002218 , ...,  0.03128231,\n",
      "          -0.00020381,  0.04286098]],\n",
      "\n",
      "        [[-0.03849304, -0.03692238, -0.00840852, ...,  0.00096299,\n",
      "          -0.05464651,  0.03211782],\n",
      "         [-0.00793809, -0.06659025,  0.05053774, ..., -0.00443216,\n",
      "           0.06467909,  0.05157401],\n",
      "         [ 0.0273382 , -0.01509347, -0.01955278, ..., -0.01402915,\n",
      "           0.04721088, -0.03835222],\n",
      "         ...,\n",
      "         [-0.02891088, -0.00312304, -0.04155499, ..., -0.04972351,\n",
      "          -0.05454277, -0.03271714],\n",
      "         [ 0.05195982, -0.04707608, -0.02207609, ..., -0.05963199,\n",
      "          -0.05081778, -0.06881428],\n",
      "         [ 0.01797327, -0.00596476, -0.02395797, ...,  0.01551866,\n",
      "          -0.0009438 , -0.00577915]],\n",
      "\n",
      "        [[-0.04754779, -0.06018404,  0.01433238, ...,  0.04394709,\n",
      "           0.03514169,  0.04337735],\n",
      "         [ 0.05391689,  0.02356672, -0.03557498, ..., -0.07029299,\n",
      "           0.07183811,  0.00323547],\n",
      "         [-0.03791319,  0.00658538, -0.04751001, ..., -0.02053741,\n",
      "          -0.03193739, -0.06727799],\n",
      "         ...,\n",
      "         [ 0.01203328,  0.06198494,  0.06969039, ..., -0.03729271,\n",
      "           0.00825321,  0.03165939],\n",
      "         [-0.02685489, -0.04720871,  0.06368741, ...,  0.05543426,\n",
      "           0.0243473 , -0.03275876],\n",
      "         [ 0.03043457,  0.01900502,  0.02656193, ..., -0.00893226,\n",
      "           0.03011613, -0.00533962]]]], dtype=float32)>,\n",
      " <tf.Variable 'v4_conv2d_trans/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
      " <tf.Variable 'v2_conv2d_trans/kernel:0' shape=(1, 1, 4, 64) dtype=float32, numpy=\n",
      "array([[[[-0.03191641, -0.25824973,  0.18460226,  0.06893137,\n",
      "          -0.07549265, -0.14530383,  0.21795982, -0.00652876,\n",
      "           0.20014983, -0.08976185,  0.00569704,  0.0931026 ,\n",
      "           0.21863532, -0.09750654,  0.25145745,  0.11818615,\n",
      "          -0.15309645, -0.04316935, -0.18880866,  0.19530082,\n",
      "          -0.02546117, -0.14597535,  0.01433492, -0.02978557,\n",
      "           0.10208964, -0.09060065,  0.2965482 , -0.26112187,\n",
      "          -0.19480734,  0.1042307 ,  0.2674685 ,  0.01919267,\n",
      "           0.01518428,  0.08025017, -0.13646771, -0.07914792,\n",
      "          -0.14328027,  0.08185187, -0.29314128, -0.29008555,\n",
      "           0.26994902,  0.20374316, -0.20439577, -0.06147522,\n",
      "           0.02231652,  0.02235857, -0.18123338, -0.08545473,\n",
      "           0.07435611,  0.10736835, -0.06676163, -0.25100115,\n",
      "           0.27594906, -0.13775921,  0.03966549, -0.25311443,\n",
      "          -0.28987056, -0.01916137, -0.10604109,  0.09361812,\n",
      "           0.19779506,  0.18912503, -0.15193804, -0.21810359],\n",
      "         [-0.13206945,  0.21292591, -0.19156536, -0.21710259,\n",
      "          -0.26131997,  0.2636568 , -0.13544251, -0.15473731,\n",
      "           0.02444476,  0.20689583, -0.06864746,  0.22261375,\n",
      "          -0.20815367,  0.2699473 , -0.07984465,  0.08963436,\n",
      "          -0.1473655 , -0.24637711, -0.10387553, -0.25063905,\n",
      "          -0.06137195, -0.14934345,  0.16084546, -0.06673777,\n",
      "           0.2744199 ,  0.29353255,  0.02523249,  0.2522062 ,\n",
      "           0.27917004,  0.19622728, -0.03356689,  0.07242873,\n",
      "          -0.1656513 ,  0.1238786 , -0.10740983,  0.05279675,\n",
      "           0.2075674 , -0.27383393, -0.26470003,  0.29218227,\n",
      "           0.03793108, -0.14208947, -0.11413443, -0.26801828,\n",
      "           0.1621531 ,  0.17095685,  0.18190503, -0.03955826,\n",
      "          -0.22998329,  0.0537245 , -0.22344814, -0.04315776,\n",
      "           0.22975099, -0.13371661,  0.0223867 ,  0.08136588,\n",
      "          -0.01607004,  0.27655905,  0.2675318 ,  0.00539902,\n",
      "           0.17601076, -0.26763442, -0.15301396,  0.24813342],\n",
      "         [ 0.23298311, -0.17040345,  0.09102231, -0.2721103 ,\n",
      "           0.0943256 ,  0.06190282, -0.11663455,  0.2253145 ,\n",
      "          -0.08422209, -0.26634273, -0.22986558,  0.23551136,\n",
      "          -0.21041505, -0.16859567, -0.05143508, -0.212127  ,\n",
      "           0.00730729,  0.02805322,  0.11983317, -0.26816174,\n",
      "           0.24655259,  0.12900561,  0.2370835 ,  0.20036253,\n",
      "          -0.13018328,  0.1373699 ,  0.10956287,  0.03879821,\n",
      "          -0.02814606, -0.23997647, -0.20733951, -0.04747202,\n",
      "          -0.13007903,  0.03532964, -0.07414357,  0.12923351,\n",
      "          -0.23318878, -0.22859865,  0.2851773 ,  0.01556423,\n",
      "          -0.01480651,  0.01311707, -0.0151386 ,  0.08377174,\n",
      "           0.27448422, -0.05128098,  0.17919537, -0.08773148,\n",
      "          -0.09641065, -0.23703803, -0.2277112 , -0.10352723,\n",
      "          -0.18802021, -0.03982335,  0.10430619,  0.25225788,\n",
      "           0.21752477,  0.27780104,  0.06787756, -0.17993855,\n",
      "           0.09175164,  0.03528884, -0.02446428, -0.0008505 ],\n",
      "         [ 0.05203471,  0.29333246,  0.0339382 ,  0.12580019,\n",
      "           0.19001403, -0.1694747 , -0.15149732,  0.10248971,\n",
      "           0.00801361, -0.23410931, -0.11896193, -0.2228252 ,\n",
      "          -0.28032467,  0.24142522, -0.24410504, -0.01138672,\n",
      "          -0.09090815,  0.08197439, -0.00033343,  0.08808303,\n",
      "           0.25528878, -0.29626262,  0.16546002,  0.16790417,\n",
      "          -0.17976674,  0.03193164, -0.0136624 ,  0.1156691 ,\n",
      "          -0.22692367, -0.12850001, -0.15811993,  0.2687291 ,\n",
      "           0.18905336,  0.22355413,  0.11929268, -0.00286514,\n",
      "          -0.04579142, -0.02386677, -0.2162373 , -0.23143518,\n",
      "          -0.14647833, -0.10911931,  0.02412826,  0.05340084,\n",
      "           0.01781458, -0.25276026, -0.26582474,  0.14095932,\n",
      "           0.28156155, -0.02049968,  0.07070366,  0.27893013,\n",
      "           0.01752695, -0.14444618, -0.14174274, -0.17569059,\n",
      "           0.15969032, -0.06686659,  0.17688087, -0.05710869,\n",
      "          -0.10335548,  0.07972264, -0.09065171, -0.01378089]]]],\n",
      "      dtype=float32)>,\n",
      " <tf.Variable 'v2_conv2d_trans/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "autoencoder = Model(v1_filtered_output, decoder_output, name='v1_to_pulvinar_vae')\n",
    "autoencoder.summary()\n",
    "pprint.pprint(autoencoder.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# set up paths\n",
    "nih_cxr8_base = os.path.sep.join(['\\\\\\\\KRAMPUS-16', 'DataAll', 'NIH_Cxr8'])\n",
    "nih_cxr8_csv = os.path.sep.join([nih_cxr8_base, 'Data_Entry_2017_v2020.csv'])\n",
    "logging.info(f\"Reading from {nih_cxr8_csv}\")\n",
    "\n",
    "# read the csv dataset\n",
    "cxr_batched_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern=nih_cxr8_csv, \n",
    "    batch_size=batch_size, num_epochs=1, num_parallel_reads=20,\n",
    "    shuffle=False)\n",
    "\n",
    "# look at first 50\n",
    "cxr_batched_ds = cxr_batched_ds.take(50)\n",
    "\n",
    "# filter for No Finding\n",
    "nofinding_cxrs = \\\n",
    "    cxr_batched_ds.filter(\n",
    "        lambda item: tf.equal(item['Finding Labels'][0], 'No Finding'))\n",
    "\n",
    "# show a few\n",
    "for batch in nofinding_cxrs.take(3):\n",
    "    logging.info(\"-----------\")\n",
    "    for item in batch:\n",
    "        logging.info(f\"{item}: {batch[item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform single epoch\n",
    "for batch_x_in in train_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "        batch_x_pred = autoencoder(batch_x_in)\n",
    "        loss = vae_loss(z_mean, z_log_var, batch_x_in, batch_x_pred)\n",
    "    grads = tape.gradient(loss, autoencoder.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, autoencoder.trainable_variables))\n",
    "    print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit0c83dea770f14d06900285e7e16051d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
