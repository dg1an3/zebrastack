{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from read_imageset import read_imageset_arrays\n",
    "from build_autoencoder import build_autoencoder\n",
    "from show_original_decoded import show_original_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2c896381bcaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'LIDC-IDRI'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_imageset_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\github\\dg1an3\\zebrastack\\keras_autoencoder\\read_imageset.py\u001b[0m in \u001b[0;36mread_imageset_arrays\u001b[1;34m(dataset_name, sz, frac)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mslice_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_imageset_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mslice_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_arrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0msuper_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_arrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "sz = 128\n",
    "dataset_name = 'LIDC-IDRI'\n",
    "x_train = read_imageset_arrays(dataset_name, sz, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(random.sample(list(x_train), int(len(x_train)/10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encode_only, decode_only = build_autoencoder(sz, 'adadelta', 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train, \n",
    "                epochs=250, batch_size=256, \n",
    "                shuffle=True, validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model(s)\n",
    "autoencoder.save('models/autoencoder.h5')\n",
    "encode_only.save('models/encode_only.h5')\n",
    "decode_only.save('models/decode_only.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_only_imgs = encode_only.predict(x_test)\n",
    "for n in range(10):\n",
    "    print(\"shape of encoded = \", encode_only_imgs[2].shape)\n",
    "    hist, bins = np.histogram(encode_only_imgs[2])\n",
    "    print(hist)\n",
    "    print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random values to decoded\n",
    "for n in range(8):\n",
    "    perturb_vectors = np.zeros(encode_only_imgs[2].shape)\n",
    "    perturb_element = -120.0 # * np.random.standard_normal()\n",
    "    perturb_vectors[:,n] = perturb_element\n",
    "    encode_only_imgs_z = np.add(encode_only_imgs[2], perturb_vectors)\n",
    "\n",
    "    decoded_imgs = decode_only.predict(encode_only_imgs_z)\n",
    "    show_original_decoded(x_test, decoded_imgs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random values to decoded\n",
    "perturb_vectors = np.random.standard_normal(size=encode_only_imgs[2].shape)\n",
    "perturb_vectors = np.multiply(perturb_vectors, 15.8)\n",
    "encode_only_imgs_z = np.add(encode_only_imgs[2], perturb_vectors)\n",
    "\n",
    "decoded_imgs = decode_only.predict(encode_only_imgs_z)\n",
    "show_original_decoded(x_test, decoded_imgs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_encoded = 0.0 * np.random.standard_normal(size=encode_only_imgs[2].shape)\n",
    "print(random_encoded.shape)\n",
    "print(type(random_encoded))\n",
    "decoded_imgs_original = decode_only.predict(random_encoded)\n",
    "\n",
    "perturb_vectors = np.random.standard_normal(size=encode_only_imgs[2].shape)\n",
    "perturb_vectors = np.multiply(perturb_vectors, 5.0)\n",
    "decoded_imgs_perturbed = decode_only.predict(np.add(random_encoded, perturb_vectors))\n",
    "\n",
    "show_original_decoded(decoded_imgs_original, decoded_imgs_perturbed, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def g(**kwargs):\n",
    "    plt.figure(2)\n",
    "    # x = np.linspace(-10,10,num=1000)\n",
    "    # plt.plot(x,kwargs['1']/100*x + kwargs['2'])\n",
    "    # plt.ylim(-5,5)\n",
    "    # plt.show()\n",
    "    latent = np.array([list(kwargs.values())])\n",
    "    # print(type(latent))\n",
    "    # print(latent.shape)\n",
    "    # latent.reshape(1,)\n",
    "    # print(latent)\n",
    "    decoded = decode_only.predict(latent)\n",
    "    plt.imshow(decoded.reshape(sz,sz))\n",
    "    plt.gray()\n",
    "    return kwargs['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive_output,Layout\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "latent_dim = encode_only_imgs[2].shape[-1]\n",
    "kwargs = {str(k):widgets.IntSlider(value=0,min=-20,max=20,orientation='vertical',layout=Layout(padding='0%')) for k in range(latent_dim)}\n",
    "w = interactive_output(g,kwargs)\n",
    "display(widgets.HBox(list(kwargs.values()),layout=Layout(padding='0%')),w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_only_imgs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!where cudart64_100.dll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit0c83dea770f14d06900285e7e16051d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
