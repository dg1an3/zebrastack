{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_directory = '.\\Data'\n",
    "datasets = [(path, files) for path, _, files in os.walk(dataset_directory) if len(files) > 0]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize, rescale\n",
    "\n",
    "imgs = [mpimg.imread(dn+'\\\\'+fn) for (dn,fns) in datasets for fn in fns]\n",
    "print('Resizing...', [img.shape for img in imgs])\n",
    "augment_imgs = True # False\n",
    "if augment_imgs:\n",
    "    import random    \n",
    "    imgs = [crop(img, ((random.randint(0,25),random.randint(0,25)),(random.randint(0,25),random.randint(0,25)),(0,0))) for img in imgs]\n",
    "imgs_128 = [resize(img, (128,128), anti_aliasing=True) for img in imgs]\n",
    "print('Done resizing.', [img.shape for img in imgs_128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def shift_hsv(hsv, shift_h, shift_v=0.0):\n",
    "    h_new = hsv[0] + shift_h\n",
    "    if (h_new > 1.0):\n",
    "        h_new = h_new - 1.0\n",
    "    v_new = hsv[2] + shift_v\n",
    "    v_new = min(v_new, 1.0)\n",
    "    v_new = max(v_new, 0.0)\n",
    "    return [h_new,hsv[1],v_new]\n",
    "print(shift_hsv([0.9,0.3,0.5], 0.39, shift_v=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import crop, pad\n",
    "import numpy as np\n",
    "\n",
    "x_train = []\n",
    "fig, axes = plt.subplots(3,len(imgs_128),sharey=True, figsize=(18,20))\n",
    "for shift_h in range(3):\n",
    "    for n in range(len(imgs_128)):\n",
    "        img_hsv = colors.rgb_to_hsv(imgs_128[n])\n",
    "        img_hsv = np.apply_along_axis(shift_hsv, 2, img_hsv, shift_h=shift_h/12.0, shift_v=0.0)\n",
    "        x_train.append(imgs_128[n])\n",
    "        # print(img_hsv.shape)\n",
    "        axes[shift_h][n].imshow(colors.hsv_to_rgb(img_hsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, SpatialDropout2D\n",
    "from keras.layers import Conv2D, Flatten, Lambda\n",
    "from keras.layers import LocallyConnected2D, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.layers import ActivityRegularization\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# then z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(sz, optimizer, loss):\n",
    "\n",
    "    # create encoder side\n",
    "    input_img = Input(shape=(sz,sz,3))\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = LocallyConnected2D(32, (3,3))(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    "    x = MaxPooling2D((2,2), padding='same')(x)\n",
    "    encoded_layer = ActivityRegularization(l1=0.0e-4,l2=0.0e-4)(x)\n",
    "\n",
    "    # shape info needed to build decoder model\n",
    "    shape = K.int_shape(encoded_layer)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    latent_dim = 3\n",
    "    x = Flatten()(encoded_layer)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "\n",
    "    encoder = Model(input_img, [z_mean, z_log_var, z], name='encoder')\n",
    "    encoder.summary()\n",
    "    # plot_model(encoder, to_file='data\\dicom_encoder.png', show_shapes=True)\n",
    "\n",
    "    # TODO: add threshold layer for sparsity test\n",
    "\n",
    "\n",
    "\n",
    "    # build decoder model\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "    x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "    x = LocallyConnected2D(32, (3,3))(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2DTranspose(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2DTranspose(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2DTranspose(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    decoded_layer = Conv2D(3, (3,3), activation='sigmoid', padding='same')(x)\n",
    "    decoder = Model(latent_inputs, decoded_layer)\n",
    "    decoder.summary()\n",
    "    # plot_model(decoder, to_file='data\\dicom_decoder.png', show_shapes=True)\n",
    "\n",
    "    autoencoder_output = decoder(encoder(input_img)[2])\n",
    "    autoencoder = Model(input_img, autoencoder_output, name='ae')\n",
    "    autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "    autoencoder.summary()\n",
    "    # plot_model(autoencoder, to_file='data\\dicom_autoencoder.png', show_shapes=True)\n",
    "\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae, enc, dec = build_autoencoder(128, 'adadelta', 'categorical_crossentropy') # 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "len(x_train), [data.shape for data in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "x_test = np.array(random.sample(list(x_train), int(len(x_train)/2)))\n",
    "vae.fit(x_train, x_train, epochs=500, batch_size=256, \n",
    "        shuffle=True, validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array(random.sample(list(x_train), int(len(x_train)/2)))\n",
    "print(x_test.shape)\n",
    "encode_only_imgs = enc.predict(x_test)[2]   # z parameter is #2\n",
    "print(encode_only_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(len(encode_only_imgs)):\n",
    "print(\"shape of encoded = \", encode_only_imgs.shape)\n",
    "print(\"encoded = \", encode_only_imgs)\n",
    "hist, bins = np.histogram(encode_only_imgs)\n",
    "print(hist)\n",
    "print(bins)\n",
    "\n",
    "# add random values to decoded\n",
    "perturb_vectors = np.random.standard_normal(size=encode_only_imgs.shape)\n",
    "perturb_vectors = np.multiply(perturb_vectors, 0.1)\n",
    "# encode_only_imgs_z = encode_only_imgs # \n",
    "encode_only_imgs_z = np.add(encode_only_imgs, perturb_vectors)\n",
    "\n",
    "decoded_imgs = dec.predict(encode_only_imgs_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_original_decoded(original, decoded, sz):\n",
    "    n = 3  # how many digits we will display\n",
    "    plt.figure(figsize=(n*2, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        # plt.imshow(colors.hsv_to_rgb(original[i].reshape(128, 128, 3)))       \n",
    "        plt.imshow(original[i].reshape(128, 128, 3))\n",
    "        ax = plt.subplot(2, n, i+1+n)\n",
    "        plt.imshow(decoded[i])\n",
    "    plt.show() # block=True)\n",
    "show_original_decoded(x_test, decoded_imgs, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
